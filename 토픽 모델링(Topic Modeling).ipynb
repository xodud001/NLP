{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "964cc6a6",
   "metadata": {},
   "source": [
    "# 토픽 모델링(Topic Modeling)\n",
    "토픽 모델링(Topic Modeling)이란 기계 학습 및 자연어 처리 분야에서 토픽이라는 문서 집합의 추상적인 주제를 발견하기 위한 통계적 모델 중 하나\n",
    "\n",
    "텍스트 본문의 숨겨진 의미 구조를 발견하기 위해 사용되는 텍스트 마이닝 기법\n",
    "\n",
    "# 잠재 의미 분석(Latent Semantic Analysis, LSA)\n",
    "BoW에 기반한 DTM이나 TF-IDF는 기본적으로 단어의 빈도 수를 이용한 수치화 방법이기 때문에 단어의 의미를 고려하지 못한다는 단점이 있음\n",
    "\n",
    "이를 위한 대안으로 DTM의 잠재된(Latent) 의미를 이끌어내는 방법으로 잠재 의미 분석(Latent Semantic Analysis, LSA)이라는 방법이 있음\n",
    "\n",
    "LSA는 기본적으로 DTM이나 TF-IDF 행렬에 절단된 SVD(truncated SVD)를 사용하여 차원을 축소시키고, 단어들의 잠재적인 의미를 끌어낸다는 아이디어를 갖고 있음\n",
    "\n",
    "실습을 통해서 이해\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "위와 같은 DTM을 실제로 파이썬을 통해서 만들면 아래와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "534faefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A=np.array([[0,0,0,1,0,1,1,0,0],[0,0,0,1,1,0,1,0,0],[0,1,1,0,2,0,0,0,0],[1,0,0,0,0,0,0,1,1]])\n",
    "np.shape(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef9d0f",
   "metadata": {},
   "source": [
    "4 × 9의 크기를 가지는 DTM이 생성<br/>\n",
    "이에 대해서 풀 SVD(full SVD)를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca14488",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, VT = np.linalg.svd(A, full_matrices = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c801cd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24  0.75  0.   -0.62]\n",
      " [-0.51  0.44 -0.    0.74]\n",
      " [-0.83 -0.49 -0.   -0.27]\n",
      " [-0.   -0.    1.    0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(U.round(2))\n",
    "np.shape(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18967044",
   "metadata": {},
   "source": [
    "4 × 4의 크기를 가지는 직교 행렬 U가 생성됨. 이제 대각 행렬 S를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9d022a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.69 2.05 1.73 0.77]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(s.round(2))\n",
    "np.shape(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e525a",
   "metadata": {},
   "source": [
    "Numpy의 linalg.svd()는 특이값 분해의 결과로 대각 행렬이 아니라 특이값의 리스트를 반환.\n",
    "그러므로 앞서 본 수식의 형식으로 보려면 이를 다시 대각 행렬로 바꾸어 주어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b679b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.zeros((4, 9)) # 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성\n",
    "S[:4, :4] = np.diag(s) # 특이값을 대각행렬에 삽입\n",
    "print(S.round(2))\n",
    "np.shape(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf6f36",
   "metadata": {},
   "source": [
    "4 × 9의 크기를 가지는 대각 행렬 S가 생성되었음. 2.69 > 2.05 > 1.73 > 0.77 순으로 값이 내림차순을 보이는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "737dbb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
      " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
      " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
      " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
      " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
      " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(VT.round(2))\n",
    "np.shape(VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9966138",
   "metadata": {},
   "source": [
    "9 × 9의 크기를 가지는 직교 행렬 VT(V의 전치 행렬)가 생성되었습니다. 즉, U × S × VT를 하면 기존의 행렬 A가 나와야 함.\n",
    "\n",
    "Numpy의 allclose()는 2개의 행렬이 동일하면 True를 리턴. Numpy의 allclose()는 2개의 행렬이 동일하면 True를 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb9ab0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A, np.dot(np.dot(U,S), VT).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22dd3b",
   "metadata": {},
   "source": [
    "지금까지 수행한 것은 풀 SVD(Full SVD). 이제 t를 정하고, 절단된 SVD(Truncated SVD)를 수행.\n",
    "\n",
    "여기서는 t=2로 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3858cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.69 0.  ]\n",
      " [0.   2.05]]\n"
     ]
    }
   ],
   "source": [
    "S=S[:2,:2]\n",
    "print(S.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8507670",
   "metadata": {},
   "source": [
    "상위 2개의 값만 남기고 나머지는 모두 제거된 것을 볼 수 있음. 이제 직교 행렬 U에 대해서도 2개의 열만 남기고 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a731364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24  0.75]\n",
      " [-0.51  0.44]\n",
      " [-0.83 -0.49]\n",
      " [-0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "U=U[:,:2]\n",
    "print(U.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750def4",
   "metadata": {},
   "source": [
    "2개의 열만 남기고 모두 제거된 것을 확인. 이제 행렬 V의 전치 행렬인 VT에 대해서 2개의 행만 남기고 제거. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5245ea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "VT=VT[:2,:]\n",
    "print(VT.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc5bea",
   "metadata": {},
   "source": [
    "이제 축소된 행렬 U, S, VT에 대해서 다시 U × S × VT연산을 하면 기존의 A와는 다른 결과가 나오게 됨.\n",
    "\n",
    "값이 손실되었기 때문에 이 세 개의 행렬로는 이제 기존의 A행렬을 복구할 수 없습니다. U × S × VT연산을 해서 나오는 값을 A_prime이라 하고 기존의 행렬 A와 값을 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b21216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n",
      "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
      " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
      " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "A_prime=np.dot(np.dot(U,S), VT)\n",
    "print(A)\n",
    "print(A_prime.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff77f36",
   "metadata": {},
   "source": [
    "대체적으로 기존에 0인 값들은 0에 가가운 값이 나오고, 1인 값들은 1에 가까운 값이 나오는 것을 확인\n",
    "\n",
    "## 실습을 통한 이해\n",
    "사이킷런에서는 Twenty Newsgroups이라고 불리는 20개의 다른 주제를 가진 뉴스그룹 데이터를 제공\n",
    "\n",
    "여기서는 LSA를 사용해서 문서의 수를 원하는 토픽의 수로 압축한 뒤에 각 토픽당 가장 중요한 단어 5개를 출력하는 실습으로 토픽 모델링을 수행\n",
    "\n",
    "### 뉴스그룹 데이터에 대한 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faaa24eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20ceddf",
   "metadata": {},
   "source": [
    "훈련에 사용할 뉴스그룹 데이터는 총 11,314개입니다. 이 중 첫번째 훈련용 샘플을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73556282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4943da0",
   "metadata": {},
   "source": [
    "뉴스그룹 데이터에는 특수문자가 포함된 다수의 영어문장으로 구성되어져 있음. 이런 형식의 샘플이 총 11,314개 존재합니다. 사이킷런이 제공하는 뉴스그룹 데이터에서 target_name에는 본래 이 뉴스그룹 데이터가 어떤 20개의 카테고리를 갖고있었는지가 저장되어져 있습니다. 이를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7326a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5847b36",
   "metadata": {},
   "source": [
    "## 텍스트 전처리\n",
    "작하기 앞서, 텍스트 데이터에 대해서 가능한한 정제 과정을 거쳐야만 함\n",
    "\n",
    "기본적인 아이디어는 알파벳을 제외한 구두점, 숫자, 특수 문자를 제거하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f1ac20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-b4124dfb5e6a>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    }
   ],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "# 특수 문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54de97fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc7dd8",
   "metadata": {},
   "source": [
    "불용어를 제거하기 위해서 토큰화를 우선 수행. 후에 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c85b43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english') # NLTK로부터 불용어를 받아옵니다.\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "# 불용어를 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dea60f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_doc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eddd3e7",
   "metadata": {},
   "source": [
    "## TF-IDF 행렬 만들기\n",
    "불용어 제거를 위해 토큰화 작업을 수행하였지만, TfidfVectorizer(TF-IDF 챕터 참고)는 기본적으로 토큰화가 되어있지 않은 텍스트 데이터를 입력으로 사용.\n",
    "\n",
    "그렇기 때문에 TfidfVectorizer를 사용해서 TF-IDF 행렬을 만들기 위해서 다시 토큰화 작업을 역으로 취소하는 작업을 수행. 이를 역토큰화라 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e937d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgroup atheist hard bummin much forget flintstone chewables bake timmons'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 역토큰화 (토큰화 작업을 역으로 되돌림)\n",
    "detokenized_doc = []\n",
    "for i in range(len(news_df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "news_df['clean_doc'] = detokenized_doc\n",
    "\n",
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc613a",
   "metadata": {},
   "source": [
    "정상적으로 불용어가 제거된 상태에서 역토큰화가 수행되었음을 확인\n",
    "\n",
    "이제 사이킷런의 TfidfVectorizer를 통해 단어 1,000개에 대한 TF-IDF 행렬을 만들 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21d47689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "max_features= 1000, # 상위 1,000개의 단어를 보존 \n",
    "max_df = 0.5, \n",
    "smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "X.shape # TF-IDF 행렬의 크기 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0402cb",
   "metadata": {},
   "source": [
    "## 토픽 모델링(Topic Modeling)\n",
    "이제 TF-IDF 행렬을 다수의 행렬로 분해. 여기서는 사이킷런의 절단된 SVD(Truncated SVD)를 사용\n",
    "\n",
    "원래 기존 뉴스그룹 데이터가 20개의 카테고리를 갖고있었기 때문에, 20개의 토픽을 가졌다고 가정하고 토픽 모델링을 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "250aacc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
    "svd_model.fit(X)\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52af520b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(svd_model.components_)#svd_modle은 VT에 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b68dc",
   "metadata": {},
   "source": [
    "정확하게 토픽의 수 t × 단어의 수의 크기를 가지는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44492f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('like', 0.21386), ('know', 0.20046), ('people', 0.19293), ('think', 0.17805), ('good', 0.15128)]\n",
      "Topic 2: [('thanks', 0.32888), ('windows', 0.29088), ('card', 0.18069), ('drive', 0.17455), ('mail', 0.15111)]\n",
      "Topic 3: [('game', 0.37064), ('team', 0.32443), ('year', 0.28154), ('games', 0.2537), ('season', 0.18419)]\n",
      "Topic 4: [('drive', 0.53324), ('scsi', 0.20165), ('hard', 0.15628), ('disk', 0.15578), ('card', 0.13994)]\n",
      "Topic 5: [('windows', 0.40399), ('file', 0.25436), ('window', 0.18044), ('files', 0.16078), ('program', 0.13894)]\n",
      "Topic 6: [('chip', 0.16114), ('government', 0.16009), ('mail', 0.15625), ('space', 0.1507), ('information', 0.13562)]\n",
      "Topic 7: [('like', 0.67086), ('bike', 0.14236), ('chip', 0.11169), ('know', 0.11139), ('sounds', 0.10371)]\n",
      "Topic 8: [('card', 0.46633), ('video', 0.22137), ('sale', 0.21266), ('monitor', 0.15463), ('offer', 0.14643)]\n",
      "Topic 9: [('know', 0.46047), ('card', 0.33605), ('chip', 0.17558), ('government', 0.1522), ('video', 0.14356)]\n",
      "Topic 10: [('good', 0.42756), ('know', 0.23039), ('time', 0.1882), ('bike', 0.11406), ('jesus', 0.09027)]\n",
      "Topic 11: [('think', 0.78469), ('chip', 0.10899), ('good', 0.10635), ('thanks', 0.09123), ('clipper', 0.07946)]\n",
      "Topic 12: [('thanks', 0.36824), ('good', 0.22729), ('right', 0.21559), ('bike', 0.21037), ('problem', 0.20894)]\n",
      "Topic 13: [('good', 0.36212), ('people', 0.33985), ('windows', 0.28385), ('know', 0.26232), ('file', 0.18422)]\n",
      "Topic 14: [('space', 0.39946), ('think', 0.23258), ('know', 0.18074), ('nasa', 0.15174), ('problem', 0.12957)]\n",
      "Topic 15: [('space', 0.31613), ('good', 0.3094), ('card', 0.22603), ('people', 0.17476), ('time', 0.14496)]\n",
      "Topic 16: [('people', 0.48156), ('problem', 0.19961), ('window', 0.15281), ('time', 0.14664), ('game', 0.12871)]\n",
      "Topic 17: [('time', 0.34465), ('bike', 0.27303), ('right', 0.25557), ('windows', 0.1997), ('file', 0.19118)]\n",
      "Topic 18: [('time', 0.5973), ('problem', 0.15504), ('file', 0.14956), ('think', 0.12847), ('israel', 0.10903)]\n",
      "Topic 19: [('file', 0.44163), ('need', 0.26633), ('card', 0.18388), ('files', 0.17453), ('right', 0.15448)]\n",
      "Topic 20: [('problem', 0.33006), ('file', 0.27651), ('thanks', 0.23578), ('used', 0.19206), ('space', 0.13185)]\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
    "\n",
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "get_topics(svd_model.components_,terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00d6e6",
   "metadata": {},
   "source": [
    "## LSA의 장단점(Pros and Cons of LSA)\n",
    "정리해보면 LSA는 쉽고 빠르게 구현이 가능할 뿐만 아니라 단어의 잠재적인 의미를 이끌어낼 수 있어 문서의 유사도 계산 등에서 좋은 성능을 보여준다는 장점을 갖고 있음.\n",
    "\n",
    "하지만 SVD의 특성상 이미 계산된 LSA에 새로운 데이터를 추가하여 계산하려고하면 보통 처음부터 다시 계산해야 함\n",
    "\n",
    "# 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)\n",
    "잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)은 토픽 모델링의 대표적인 알고리즘\n",
    "\n",
    "## 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA) 개요\n",
    "우선 LDA의 내부 메커니즘에 대해서 이해하기 전에, LDA를 일종의 블랙 박스로 보고 LDA에 문서 집합을 입력하면, 어떤 결과를 보여주는지 간소화 된 예를 들어 보겠습니다.\n",
    "\n",
    "* 문서1 : 저는 사과랑 바나나를 먹어요\n",
    "* 문서2 : 우리는 귀여운 강아지가 좋아요\n",
    "* 문서3 : 저의 깜찍하고 귀여운 강아지가 바나나를 먹어요\n",
    "\n",
    "LDA를 수행할 때 문서 집합에서 토픽이 몇 개가 존재할지 가정하는 것은 사용자가 해야 할 일. 여기서는 LDA에 2개의 토픽을 찾으라고 요청\n",
    "\n",
    "LDA는 각 문서의 토픽 분포와 각 토픽 내의 단어 분포를 추정\n",
    "\n",
    "<b><각 문서의 토픽 분포></b><br/>\n",
    "문서1 : 토픽 A 100%<br/>\n",
    "문서2 : 토픽 B 100%<br/>\n",
    "문서3 : 토픽 B 60%, 토픽 A 40%<br/>\n",
    "\n",
    "<b><각 토픽의 단어 분포></b><br/>\n",
    "토픽A : 사과 20%, 바나나 40%, 먹어요 40%, 귀여운 0%, 강아지 0%, 깜찍하고 0%, 좋아요 0%<br/>\n",
    "토픽B : 사과 0%, 바나나 0%, 먹어요 0%, 귀여운 33%, 강아지 33%, 깜찍하고 16%, 좋아요 16%\n",
    "    \n",
    "LDA는 토픽의 제목을 정해주지 않지만, 이 시점에서 알고리즘의 사용자는 위 결과로부터 두 토픽이 각각 과일에 대한 토픽과 강아지에 대한 토픽이라고 판단해볼 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91855011",
   "metadata": {},
   "source": [
    "## LDA의 가정\n",
    "LDA는 문서의 집합으로부터 어떤 토픽이 존재하는지를 알아내기 위한 알고리즘\n",
    "\n",
    "LDA는 단어의 순서는 신경쓰지 않음\n",
    "\n",
    "## LDA의 수행하기\n",
    "이제 LDA의 수행 과정을 정리\n",
    "\n",
    "<b>1) 사용자는 알고리즘에게 토픽의 개수 k를 알려줍니다.</b><br/>\n",
    "<b>2) 모든 단어를 k개 중 하나의 토픽에 할당합니다.</b><br/>\n",
    "<b>3) 이제 모든 문서의 모든 단어에 대해서 아래의 사항을 반복 진행합니다. (iterative)</b><br/>\n",
    "<b>3-1) 어떤 문서의 각 단어 w는 자신은 잘못된 토픽에 할당되어져 있지만, 다른 단어들은 전부 올바른 토픽에 할당되어져 있는 상태라고 가정합니다. 이에 따라 단어 w는 아래의 두 가지 기준에 따라서 토픽이 재할당됩니다.</b><br/>\n",
    "- p(topic t | document d) : 문서 d의 단어들 중 토픽 t에 해당하는 단어들의 비율\n",
    "- p(word w | topic t) : 각 토픽들 t에서 해당 단어 w의 분포\n",
    "\n",
    "## 잠재 디리클레 할당과 잠재 의미 분석의 차이\n",
    "LSA : DTM을 차원 축소 하여 축소 차원에서 근접 단어들을 토픽으로 묶는다.<br/>\n",
    "LDA : 단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하여 토픽을 추출한다.\n",
    "\n",
    "## 실습을 통한 이해\n",
    "이번 챕터에서는 gensim을 사용\n",
    "\n",
    "### 정수 인코딩과 단어 집합 만들기\n",
    "바로 이전 챕터인 LSA 챕터에서 사용하였던 Twenty Newsgroups이라고 불리는 20개의 다른 주제를 가진 뉴스 데이터를 다시 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3a285e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [well, sure, story, seem, biased, disagree, st...\n",
       "1    [yeah, expect, people, read, actually, accept,...\n",
       "2    [although, realize, principle, strongest, poin...\n",
       "3    [notwithstanding, legitimate, fuss, proposal, ...\n",
       "4    [well, change, scoring, playoff, pool, unfortu...\n",
       "Name: clean_doc, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312d7ca",
   "metadata": {},
   "source": [
    "여기서는 각 단어를 (word_id, word_frequency)의 형태로 바꾸고자 합니다\n",
    "\n",
    "word_id는 단어가 정수 인코딩된 값이고, word_frequency는 해당 뉴스에서의 해당 단어의 빈도수를 의미\n",
    "\n",
    "이는 gensim의 corpora.Dictionary()를 사용하여 손쉽게 구할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "197edcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(tokenized_doc)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
    "print(corpus[1]) # 수행된 결과에서 두번째 뉴스 출력. 첫번째 문서의 인덱스는 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee8555d",
   "metadata": {},
   "source": [
    "위의 출력 결과 중에서 (66, 2)는 정수 인코딩이 66으로 할당된 단어가 두번째 뉴스에서는 두 번 등장하였음을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed68cb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faith\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[66])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a58b76",
   "metadata": {},
   "source": [
    "기존에는 단어 'faith'이었음을 알 수 있습니다. 총 학습된 단어의 개수를 확인해보겠습니다. 이는 dictionary의 길이를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47ec2574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64281"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0de3fd",
   "metadata": {},
   "source": [
    "### LDA 모델 훈련시키기\n",
    "기존의 뉴스 데이터가 총 20개의 카테고리를 가지고 있었으므로 토픽의 개수를 20으로 하여 LDA 모델을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "745e7cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.032*\"sale\" + 0.031*\"price\" + 0.027*\"offer\" + 0.026*\"shipping\"')\n",
      "(1, '0.018*\"government\" + 0.011*\"president\" + 0.010*\"public\" + 0.010*\"encryption\"')\n",
      "(2, '0.013*\"year\" + 0.008*\"april\" + 0.008*\"university\" + 0.006*\"washington\"')\n",
      "(3, '0.034*\"file\" + 0.025*\"output\" + 0.025*\"window\" + 0.024*\"entry\"')\n",
      "(4, '0.022*\"period\" + 0.016*\"play\" + 0.012*\"power\" + 0.011*\"goal\"')\n",
      "(5, '0.030*\"guns\" + 0.017*\"firearms\" + 0.017*\"weapons\" + 0.015*\"control\"')\n",
      "(6, '0.016*\"game\" + 0.014*\"team\" + 0.011*\"year\" + 0.010*\"games\"')\n",
      "(7, '0.017*\"would\" + 0.014*\"people\" + 0.011*\"think\" + 0.008*\"know\"')\n",
      "(8, '0.014*\"texas\" + 0.007*\"pitch\" + 0.006*\"alan\" + 0.005*\"peak\"')\n",
      "(9, '0.033*\"bike\" + 0.014*\"ride\" + 0.014*\"judas\" + 0.011*\"riding\"')\n",
      "(10, '0.008*\"like\" + 0.007*\"would\" + 0.007*\"used\" + 0.007*\"much\"')\n",
      "(11, '0.011*\"armenian\" + 0.010*\"turkish\" + 0.009*\"jews\" + 0.007*\"armenians\"')\n",
      "(12, '0.012*\"available\" + 0.010*\"information\" + 0.007*\"mail\" + 0.007*\"file\"')\n",
      "(13, '0.029*\"jesus\" + 0.017*\"christian\" + 0.016*\"bible\" + 0.015*\"church\"')\n",
      "(14, '0.050*\"israel\" + 0.031*\"israeli\" + 0.021*\"arab\" + 0.018*\"pain\"')\n",
      "(15, '0.013*\"said\" + 0.011*\"people\" + 0.007*\"would\" + 0.007*\"know\"')\n",
      "(16, '0.013*\"pope\" + 0.012*\"stealth\" + 0.009*\"diet\" + 0.007*\"ships\"')\n",
      "(17, '0.037*\"space\" + 0.013*\"nasa\" + 0.011*\"health\" + 0.010*\"medical\"')\n",
      "(18, '0.014*\"windows\" + 0.013*\"thanks\" + 0.011*\"drive\" + 0.010*\"would\"')\n",
      "(19, '0.021*\"ground\" + 0.021*\"wire\" + 0.012*\"cover\" + 0.012*\"neutral\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 20 #20개의 토픽, k=20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfabc269",
   "metadata": {},
   "source": [
    "각 단어 앞에 붙은 수치는 단어의 해당 토픽에 대한 기여도를 보여줌\n",
    "\n",
    "만약 10개의 단어를 출력하고 싶다면 아래의 코드를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55941683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.032*\"sale\" + 0.031*\"price\" + 0.027*\"offer\" + 0.026*\"shipping\" + 0.022*\"condition\" + 0.020*\"asking\" + 0.018*\"sell\" + 0.014*\"interested\" + 0.013*\"excellent\" + 0.013*\"best\"'), (1, '0.018*\"government\" + 0.011*\"president\" + 0.010*\"public\" + 0.010*\"encryption\" + 0.008*\"security\" + 0.007*\"clipper\" + 0.007*\"states\" + 0.007*\"state\" + 0.006*\"private\" + 0.006*\"privacy\"'), (2, '0.013*\"year\" + 0.008*\"april\" + 0.008*\"university\" + 0.006*\"washington\" + 0.006*\"jobs\" + 0.006*\"week\" + 0.005*\"last\" + 0.005*\"york\" + 0.005*\"national\" + 0.005*\"school\"'), (3, '0.034*\"file\" + 0.025*\"output\" + 0.025*\"window\" + 0.024*\"entry\" + 0.021*\"program\" + 0.012*\"line\" + 0.012*\"widget\" + 0.011*\"build\" + 0.008*\"application\" + 0.008*\"open\"'), (4, '0.022*\"period\" + 0.016*\"play\" + 0.012*\"power\" + 0.011*\"goal\" + 0.009*\"pittsburgh\" + 0.009*\"calgary\" + 0.009*\"kings\" + 0.009*\"scorer\" + 0.009*\"puck\" + 0.008*\"detroit\"'), (5, '0.030*\"guns\" + 0.017*\"firearms\" + 0.017*\"weapons\" + 0.015*\"control\" + 0.014*\"crime\" + 0.013*\"weapon\" + 0.011*\"carry\" + 0.008*\"police\" + 0.008*\"criminals\" + 0.008*\"self\"'), (6, '0.016*\"game\" + 0.014*\"team\" + 0.011*\"year\" + 0.010*\"games\" + 0.009*\"good\" + 0.008*\"season\" + 0.008*\"last\" + 0.007*\"players\" + 0.007*\"league\" + 0.007*\"hockey\"'), (7, '0.017*\"would\" + 0.014*\"people\" + 0.011*\"think\" + 0.008*\"know\" + 0.008*\"like\" + 0.006*\"even\" + 0.006*\"many\" + 0.006*\"well\" + 0.006*\"believe\" + 0.005*\"time\"'), (8, '0.014*\"texas\" + 0.007*\"pitch\" + 0.006*\"alan\" + 0.005*\"peak\" + 0.005*\"wordperfect\" + 0.005*\"wanna\" + 0.005*\"gainey\" + 0.005*\"boggs\" + 0.005*\"gary\" + 0.005*\"sandberg\"'), (9, '0.033*\"bike\" + 0.014*\"ride\" + 0.014*\"judas\" + 0.011*\"riding\" + 0.011*\"motorcycle\" + 0.010*\"bikes\" + 0.009*\"master\" + 0.009*\"slave\" + 0.008*\"kent\" + 0.006*\"rider\"'), (10, '0.008*\"like\" + 0.007*\"would\" + 0.007*\"used\" + 0.007*\"much\" + 0.006*\"good\" + 0.006*\"time\" + 0.005*\"also\" + 0.004*\"power\" + 0.004*\"back\" + 0.004*\"well\"'), (11, '0.011*\"armenian\" + 0.010*\"turkish\" + 0.009*\"jews\" + 0.007*\"armenians\" + 0.007*\"world\" + 0.006*\"turkey\" + 0.006*\"history\" + 0.005*\"greek\" + 0.005*\"population\" + 0.005*\"people\"'), (12, '0.012*\"available\" + 0.010*\"information\" + 0.007*\"mail\" + 0.007*\"file\" + 0.007*\"also\" + 0.007*\"list\" + 0.007*\"files\" + 0.007*\"software\" + 0.007*\"version\" + 0.007*\"data\"'), (13, '0.029*\"jesus\" + 0.017*\"christian\" + 0.016*\"bible\" + 0.015*\"church\" + 0.012*\"christ\" + 0.011*\"christians\" + 0.009*\"faith\" + 0.008*\"john\" + 0.007*\"word\" + 0.006*\"paul\"'), (14, '0.050*\"israel\" + 0.031*\"israeli\" + 0.021*\"arab\" + 0.018*\"pain\" + 0.011*\"palestinian\" + 0.010*\"arabs\" + 0.009*\"state\" + 0.009*\"land\" + 0.009*\"jews\" + 0.008*\"peace\"'), (15, '0.013*\"said\" + 0.011*\"people\" + 0.007*\"would\" + 0.007*\"know\" + 0.006*\"time\" + 0.006*\"could\" + 0.006*\"went\" + 0.005*\"like\" + 0.005*\"back\" + 0.005*\"told\"'), (16, '0.013*\"pope\" + 0.012*\"stealth\" + 0.009*\"diet\" + 0.007*\"ships\" + 0.006*\"bishop\" + 0.005*\"christmas\" + 0.005*\"ghetto\" + 0.005*\"schism\" + 0.005*\"headache\" + 0.004*\"inflammation\"'), (17, '0.037*\"space\" + 0.013*\"nasa\" + 0.011*\"health\" + 0.010*\"medical\" + 0.009*\"research\" + 0.009*\"launch\" + 0.008*\"earth\" + 0.007*\"satellite\" + 0.007*\"center\" + 0.006*\"shuttle\"'), (18, '0.014*\"windows\" + 0.013*\"thanks\" + 0.011*\"drive\" + 0.010*\"would\" + 0.010*\"know\" + 0.010*\"anyone\" + 0.009*\"card\" + 0.009*\"like\" + 0.008*\"system\" + 0.008*\"problem\"'), (19, '0.021*\"ground\" + 0.021*\"wire\" + 0.012*\"cover\" + 0.012*\"neutral\" + 0.012*\"cable\" + 0.011*\"panel\" + 0.009*\"circuit\" + 0.009*\"electrical\" + 0.007*\"connected\" + 0.007*\"copies\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d5720f",
   "metadata": {},
   "source": [
    "### LDA 시각화 하기\n",
    "LDA 시각화를 위해서는 pyLDAvis의 설치가 필요\n",
    "``` pip install pyLDAvis ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e0e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
